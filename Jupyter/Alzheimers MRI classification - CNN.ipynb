{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24cda55f-4c93-4a9b-93f1-46e40160dc2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Alzheimer's Disease classification from anatomical MRI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "977baf45-0422-4abc-aea2-e10e685469b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### This notebook explores the use of a low-dimensional feature space to classify Alzheimer's disease from anatomical MRI images.\n",
    "\n",
    "Briefly, the pipeline involves the following steps and technical features:\n",
    "\n",
    "- Data formating and quality check\n",
    "- Custom CNN for classification\n",
    "- Hyperparameter tuning\n",
    "- Final model application\n",
    "<!-- - Transfer learning using ResNet50  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05789582-02fb-4576-b3fb-abd4638c885c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Import analysis and plotting libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e2c498f-af11-4e5a-844f-7137a3c7b8d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \"standard\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# machine learning and statistics\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.utils import plot_model\n",
    "import keras_tuner as \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from scipy.stats import false_discovery_control\n",
    "\n",
    "# Parallel computing\n",
    "import dask\n",
    "from dask.distributed import Client, progress\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# misc\n",
    "import cv2\n",
    "import magic\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c99eed1-9404-4835-bd76-f3ce56d4659b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import pyspark module\n",
    "spark = SparkSession.builder.appName(\"Brad's PySpark\").config(\"spark.memory.offHeap.enabled\",\"true\").config(\"spark.memory.offHeap.size\",\"10g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e115089e-56cd-4dcc-b762-1986a79bd547",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load and format training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffd55f3a-e85a-4051-a447-132dec2bf6e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"C:/Users/bedelman/Documents\\GitHub/Alzheimers-MRI-Classification/Alzheimer_MRI_Dataset/Data/\"\n",
    "\n",
    "'''\n",
    "Label meanings\n",
    "0 - Mild dementia\n",
    "1 - Moderate dementia\n",
    "2 - No dementia\n",
    "3 - Very mild dementia\n",
    "'''\n",
    "Lab = ['Mild', 'Moderate', 'None', 'Very Mild']\n",
    "\n",
    "train = pd.read_parquet(f\"{BASE_DIR}/train-00000-of-00001-c08a401c53fe5312.parquet\", engine=\"pyarrow\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "270fb0bd-fd17-49ee-95cc-5bf13abc8020",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Convert data to readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2722547d-cfce-4fc1-8362-224446154a53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def dict_to_image(image_dict):\n",
    "    if isinstance(image_dict, dict) and 'bytes' in image_dict:\n",
    "        byte_string = image_dict['bytes']\n",
    "        nparr = np.frombuffer(byte_string, np.uint8)\n",
    "        img = cv2.imdecode(nparr, cv2.IMREAD_GRAYSCALE)\n",
    "        return img\n",
    "    else:\n",
    "        raise TypeError(f\"Expected dictionary with 'bytes' key, got {type(image_dict)}\")\n",
    "\n",
    "train['img_arr'] = train['image'].apply(dict_to_image)\n",
    "train.drop(\"image\", axis=1, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79316728-c086-4842-8454-253a1d6f8603",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load and format test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e33fed32-016a-4778-8274-95d3425ab3ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_parquet(f\"{BASE_DIR}/test-00000-of-00001-44110b9df98c5585.parquet\", engine=\"pyarrow\")\n",
    "test.head() \n",
    "\n",
    "# Also convert to readable format\n",
    "test['img_arr'] = test['image'].apply(dict_to_image)\n",
    "test.drop(\"image\", axis=1, inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a24a7f0e-fbfc-4a51-8806-6779cf80a827",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Explore structure and visualization of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fde75e86-4688-4be3-820d-0b5ee8168b83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Distribution of the datasets (are all classes represented equally?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2acaa56-1500-4ef1-a1e4-59d8048c45a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,3)\n",
    "unique, counts = np.unique(np.asarray(train.iloc[:].label), return_counts = True)\n",
    "ax[0].bar(unique, counts)\n",
    "ax[0].set_xticks(unique)\n",
    "ax[0].set_xticklabels(Lab, rotation = 45)\n",
    "ax[0].set_title('Training')\n",
    "ax[0].set_xlabel('Class')\n",
    "ax[0].set_ylabel('# of images')\n",
    "\n",
    "ax[1].axis('off')\n",
    "\n",
    "unique, counts = np.unique(np.asarray(test.iloc[:].label), return_counts = True)\n",
    "ax[2].bar(unique, counts)\n",
    "ax[2].set_xticks(unique)\n",
    "ax[2].set_xticklabels(Lab, rotation = 45)\n",
    "ax[2].set_title('Testing')\n",
    "ax[2].set_xlabel('Class')\n",
    "ax[0].set_ylabel('# of images')\n",
    "\n",
    "# An obvious imbalance across classes, but each class seems to be balanced across training/testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b022ed5-b189-4946-b4f9-c23f3758fba2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Visually inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4cf84c61-ac2e-42ac-84f2-8bd34c4a2b69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_lab_idx = np.asarray(train.iloc[:].label)\n",
    "\n",
    "f, ax = plt.subplots(4,4)\n",
    "for lab in range(4):\n",
    "    for ex in range(4):\n",
    "    \n",
    "        class_lab = np.argwhere(train_lab_idx == 1)\n",
    "        current_idx = np.random.randint(len(class_lab)-1,size = 1)\n",
    "        current_idx = np.asarray(current_idx)\n",
    "        \n",
    "        ax[ex, lab].axis('off')\n",
    "        ax[ex, lab].imshow(train.iloc[class_lab[current_idx[0]][0]].img_arr, cmap = \"gray\")\n",
    "        if ex == 0: ax[ex, lab].set_title(Lab[lab])\n",
    "\n",
    "# Clearly, images show different slices within the brain, which may be a major confound..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04dd10a8-8bb0-451c-bdc6-4cfca23373dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## First, build a very basic custom CNN for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "536fb1c0-a654-40e8-8096-afc40afb5ec4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Format images (stored in local memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55334cca-abd1-4496-acdf-15beb21d38f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training data\n",
    "train_data = np.empty((len(train), 128, 128))\n",
    "for i in range(len(train)):\n",
    "   train_data[i, :, :] = train.iloc[i].img_arr\n",
    "\n",
    "# test data\n",
    "test_data = np.empty((len(test), 128, 128))\n",
    "for i in range(len(test)):\n",
    "   test_data[i, :, :] = test.iloc[i].img_arr\n",
    "\n",
    "# format in 3D shape that keras likes\n",
    "train_data = np.expand_dims(train_data, axis = 3)\n",
    "test_data = np.expand_dims(test_data, axis = 3)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2221ceee-990d-4ff3-81d4-bdf7d2faffb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8537629-238b-42f3-bdab-8f6c2a877f1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Resize and rescale functions\n",
    "IMG_SIZE = 128\n",
    "resize_and_rescale = keras.Sequential([\n",
    "  layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
    "  layers.Rescaling(1./255)\n",
    "])\n",
    "\n",
    "data_augmentation = keras.Sequential([\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "batch_size = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def prepare(ds, shuffle = False, augment =False):\n",
    "  # Resize and rescale all datasets.\n",
    "  ds = ds.map(lambda x, y: (resize_and_rescale(x), y),\n",
    "              num_parallel_calls = AUTOTUNE)\n",
    "\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(1000)\n",
    "\n",
    "  # Batch all datasets.\n",
    "  ds = ds.batch(batch_size)\n",
    "\n",
    "  # Use data augmentation only on the training set.\n",
    "  if augment:\n",
    "    ds = ds.map(lambda x, y: (data_augmentation(x, training = True), y),\n",
    "                num_parallel_calls = AUTOTUNE)\n",
    "\n",
    "  # Use buffered prefetching on all datasets.\n",
    "  return ds.prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7f58127-622f-43c2-9d13-7d7a7c858e3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Augment training dataset only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8721c3b-a148-485e-af59-cb634f6daeb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Verify augmentation on first image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f2eb695-46a3-426e-92a2-e9e101bd1ba4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sample dataset\n",
    "train_data_tmp = train_data[0]\n",
    "train_data_tmp = np.expand_dims(train_data_tmp, axis = 0)\n",
    "\n",
    "# apply augmentation\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_data_tmp, train_lab_idx[:1]))\n",
    "train_ds = prepare(train_ds, shuffle=True, augment=True)\n",
    "\n",
    "# view augmented images\n",
    "train_ds = train_ds.unbatch()\n",
    "images = np.asarray(list(train_ds.map(lambda x, y: x)))\n",
    "\n",
    "f, ax = plt.subplots(1,2)\n",
    "ax[0].axis('off')\n",
    "ax[0].imshow(train_data[0], cmap = \"gray\",)\n",
    "ax[0].set_title('Original', fontsize = 10)\n",
    "\n",
    "ax[1].axis('off')\n",
    "ax[1].imshow(images[0,:,:,:], cmap = \"gray\",)\n",
    "ax[1].set_title('Augmented', fontsize = 10)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93c11cfb-9e34-42c5-81cc-336c4d82c8ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Augment multiple times to generate larger training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbaee713-c6cf-4e21-b2cf-b4d6081193ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_data, train_lab_idx))\n",
    "train_ds_for_aug = train_ds\n",
    "\n",
    "for i in range(9):\n",
    "    train_aug = prepare(train_ds_for_aug, shuffle = True, augment = True)\n",
    "    train_aug = train_aug.unbatch()\n",
    "    train_aug = train_aug.map(lambda x, y: (tf.cast(x, tf.float64), y))\n",
    "    train_ds = train_ds.concatenate(train_aug)\n",
    "\n",
    "del train_aug, train_ds_for_aug\n",
    "images = np.asarray(list(train_ds.map(lambda x, y: x)))\n",
    "labels = np.asarray(list(train_ds.map(lambda x, y: y)))\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41614f62-55cb-48cd-b1d1-aa48472f1373",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Define the CNN model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f86d26d-3d1c-41b3-b193-d2d11e805d84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape = (128, 128, 1)),\n",
    "    keras.layers.Conv2D(32, (3, 3) , activation = 'relu',),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation = 'relu'), # fully connected layer\n",
    "    keras.layers.Dense(4, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6248d0bb-aca8-47bc-be4d-7760aa543ae5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "750743ad-fb12-42ec-9249-8c75b07b5141",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "# plot_model(model, to_file='simple_CNN.png', show_shapes = True, show_layer_names = True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8cb9b299-53e0-47b7-89bb-a6e8ca8f51cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cdd3187-19e9-42dd-b5ca-6b7013c4d857",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_data, to_categorical(train_lab_idx.astype('int8')), epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb7b2eba-8d0b-4218-a6c1-96bed9788ca3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### visualize model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e0f94e7-41a1-43f9-92fe-f7d45f6f5f38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history.get('loss'),'r')\n",
    "plt.plot(np.array(history.history.get('accuracy'))*100,'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9245568-f715-434e-be95-e2d3a87e4440",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "413bc7e3-782f-44a1-b9f5-ff6fe5cec93f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prob = model.predict(test_data)\n",
    "predict_classes=np.argmax(prob,axis=1)\n",
    "predict_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8a3dd36-4b6b-4cc3-a156-ac58a196755c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### evaluate accuracy and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93b144ad-5785-4d70-98c8-0f82dad43424",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_lab_idx = np.asarray(test.iloc[:].label)\n",
    "test_lab_idx\n",
    "\n",
    "plt.plot(predict_classes[0:100],'k')\n",
    "plt.plot(test_lab_idx[0:100],'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a59f3f73-75d6-4f65-be37-7aced852f850",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7e6dc37-2f01-4b72-b679-ae581e05daa8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Define parameters to tune and the corresponding parameter space\n",
    "##### (same architecture as before, but with hyperparameter ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8608ee18-9205-4820-b536-75af25024159",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "\n",
    "    model = keras.Sequential([\n",
    "    keras.Input(shape = (128, 128, 1)),  \n",
    "        \n",
    "    keras.layers.Conv2D(\n",
    "        filters = hp.Int('conv_1_filter', min_value = 32, max_value = 128, step = 16), # adding filter \n",
    "        kernel_size = hp.Choice('conv_1_kernel', values = [3,3]), # adding filter size or kernel size\n",
    "        activation = 'relu'), # activation function\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    keras.layers.Conv2D(\n",
    "        filters = hp.Int('conv_2_filter', min_value = 32, max_value = 128, step = 16),\n",
    "        kernel_size = hp.Choice('conv_2_kernel', values = [3,3]),\n",
    "        activation = 'relu'), \n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    keras.layers.Conv2D(\n",
    "        filters = hp.Int('conv_3_filter', min_value = 32, max_value = 128, step = 16),\n",
    "        kernel_size = hp.Choice('conv_3_kernel', values = [3,3]),\n",
    "        activation = 'relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(\n",
    "        units=hp.Int('dense_1_units', min_value = 128, max_value = 512, step = 32),\n",
    "        activation='relu'),\n",
    "        \n",
    "    # output layer    \n",
    "    keras.layers.Dense(4, activation = 'softmax')\n",
    "    ])\n",
    "    \n",
    "    # compile  model\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "                  loss = 'categorical_crossentropy',\n",
    "                  metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0878966c-e83a-41a9-8ff9-705a106134ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Initiate tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bac57726-1842-4130-9822-e61f8c18bb5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(build_model, objective = 'val_accuracy', max_epochs = 10, factor = 3, directory = 'my_dir', project_name = 'AD_class')\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3295b515-54bc-4fa6-8c40-75cb62974a3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Run search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37108826-ab82-47cf-8c5d-9b749b1c9ab7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# need numpy arrays rather than tensors for tuner\n",
    "train_images = np.asarray(list(train_ds.map(lambda x, y: x)))\n",
    "train_labels = np.asarray(list(train_ds.map(lambda x, y: y)))\n",
    "train_labels = to_categorical(train_labels.astype('int8'))\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_data, test_lab_idx))\n",
    "test_images = np.asarray(list(test_ds.map(lambda x, y: x)))\n",
    "test_labels = np.asarray(list(test_ds.map(lambda x, y: y)))\n",
    "test_labels = to_categorical(test_labels.astype('int8'))\n",
    "\n",
    "tuner.search(train_images, train_labels, epochs = 20, callbacks = [stop_early],\n",
    "             validation_data = (test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "575758c9-845b-4566-a614-c5be32f31395",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "Optimal parameters are as follows:\n",
    "\n",
    "Filter 1 output dim: {best_hps.get('conv_1_filter')}\n",
    "Filter 2 output dim: {best_hps.get('conv_2_filter')}\n",
    "Filter 2 output dim: {best_hps.get('conv_3_filter')}\n",
    "\n",
    "Dense layer units: {best_hps.get('units')}\n",
    "\n",
    "Learning Rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c884d7e-f94a-435e-b3a2-3f14b6b3a660",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Optimal # of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e531b7da-bcdc-40f3-a3f6-278cc7fb8b2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(train_images, train_labels, epochs = 50, validation_split = 0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6675412-edc8-41c1-9706-2a96c3a5fde4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Visualize feature maps from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c39b1dd-e38e-4dad-84a4-0d2687a4a71d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "t = test_images[0,:,:,:]\n",
    "t = np.expand_dims(t, axis = 0)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "615e838a-9ddc-4885-aab4-a66c93c1b4ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feature_map = model.predict(t)\n",
    "feature_map[0]"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "Alzheimers MRI classification - CNN",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "PYSPARK_KERNEL",
   "language": "python",
   "name": "pyspark_kernel"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
