{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "462ee6a7-2cc0-4dcd-889d-1cab01293cec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Prepares the dataset for classification by:\n",
    "- Accessing Parquet data from an AWS S3 bucket\n",
    "- Formatting and standardizing training data\n",
    "- Addressing class imbalance using synthetic data generation techniques\n",
    "- Preprocessing test data for evaluation and cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65e36a4e-bb5f-42eb-8e9f-f0395a7cf26d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# \"standard\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# misc\n",
    "import pickle, os\n",
    "from IPython.display import clear_output\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Preprocessing\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# src\n",
    "import sys\n",
    "from pathlib import Path\n",
    "script_dir = Path(os.getcwd()).parent\n",
    "src_dir = script_dir / 'src'\n",
    "sys.path.append(str(src_dir))\n",
    "from img_preprocessing import dict_to_image\n",
    "\n",
    "clear_output(wait=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create results directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = Path(os.getcwd()).parent\n",
    "results_dir = script_dir / 'results' / 'notebook_00'\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88c86944-8205-4dc3-a9ba-9d852fbe442f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Load and format training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4912930-6b72-42cd-ab99-c4f6d0e050fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Label meanings\n",
    "0 - Mild dementia\n",
    "1 - Moderate dementia\n",
    "2 - No dementia\n",
    "3 - Very mild dementia\n",
    "'''\n",
    "Lab = ['Mild', 'Moderate', 'None', 'Very Mild']\n",
    "\n",
    "# Define the path to the raw data folder\n",
    "data_dir = Path(os.getcwd()).parent / 'data' / 'raw' \n",
    "parquet_file = os.path.join(data_dir, \"train-00000-of-00001-c08a401c53fe5312.parquet\")\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_parquet(parquet_file)\n",
    "\n",
    "# Display data shape or a preview\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "722ba5cf-59c5-477b-b1fa-ce8837170fac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Convert data to readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f7f9bf2-f58d-4ce3-8aef-08034bddf7c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train['img_arr'] = train['image'].apply(dict_to_image)\n",
    "train.drop(\"image\", axis=1, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4463288-f8b0-4e62-b996-383ff115d51a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Load and convert test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38cba496-0db1-42e8-a909-5bccdd473593",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "parquet_file = os.path.join(data_dir, \"test-00000-of-00001-44110b9df98c5585.parquet\")\n",
    "test = pd.read_parquet(parquet_file)\n",
    "test.head() \n",
    "\n",
    "# Also convert to readable format\n",
    "test['img_arr'] = test['image'].apply(dict_to_image)\n",
    "test.drop(\"image\", axis=1, inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8c90a59-2056-40a7-86fa-070e086ed5f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Examine some sample images to check data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aba0af47-cd93-49ac-8bd5-83dbecd72118",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_lab_idx = np.asarray(train.iloc[:].label)\n",
    "\n",
    "f, ax = plt.subplots(4, 4, figsize=(5, 5))\n",
    "for lab in range(4):\n",
    "    for ex in range(4):\n",
    "    \n",
    "        class_lab = np.argwhere(train_lab_idx == 1)\n",
    "        current_idx = np.random.randint(len(class_lab)-1,size = 1)\n",
    "        current_idx = np.asarray(current_idx)\n",
    "        \n",
    "        ax[ex, lab].axis('off')\n",
    "        ax[ex, lab].imshow(train.iloc[class_lab[current_idx[0]][0]].img_arr, cmap = \"gray\")\n",
    "        if ex == 0: ax[ex, lab].set_title(Lab[lab])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6e166e0-d0ef-4c78-8672-69ba9c61ddf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Clearly, images show different slices within the brain, which may be a major confound..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37c1167a-06db-4d09-8ac0-d297dfd663ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Explore distribution of dataset classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c712bf20-7bb4-4a15-92d7-951d2eadf5ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "colors = ['#aec7e8', '#ffbb78', '#98df8a', '#ff9896']\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
    "unique, counts = np.unique(np.asarray(train.iloc[:].label), return_counts=True)\n",
    "ax[0].bar(unique, counts, color=colors)\n",
    "ax[0].set_xticks(unique)\n",
    "ax[0].set_xticklabels(Lab, rotation=45)\n",
    "ax[0].set_title('Training')\n",
    "ax[0].set_xlabel('Class')\n",
    "ax[0].set_ylabel('# of images')\n",
    "\n",
    "unique, counts = np.unique(np.asarray(test.iloc[:].label), return_counts=True)\n",
    "ax[1].bar(unique, counts, color=colors)\n",
    "ax[1].set_xticks(unique)\n",
    "ax[1].set_xticklabels(Lab, rotation=45)\n",
    "ax[1].set_title('Testing')\n",
    "ax[1].set_xlabel('Class')\n",
    "ax[1].set_ylabel('# of images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6809d477-1e10-4d52-8d16-59b7029afdfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We can see that there is an obvious imbalance across classes in both the training and testing sets. However, each class has been proportionally split between the two. Nevertheless, let's attempt to balance the training set such that the model sees equal numbers of each class. To avoid overfitting (e.g. simple resampling), we use the SMOTE method here to synthetically generate new data based on what is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38ba78fe-66f4-453c-8e3c-ade2660fa07c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Extract features and labels\n",
    "train_tmp = np.array([img.flatten() for img in train['img_arr']])\n",
    "train_lab_tmp = train['label']\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "train_smote, train_smote_lab = smote.fit_resample(train_tmp.reshape(-1, 128*128), train_lab_tmp)\n",
    "train_smote = train_smote.reshape(-1, 128, 128)\n",
    "\n",
    "# Create a new DataFrame with the resampled data\n",
    "train_smote = pd.DataFrame({'label': train_smote_lab, 'img_arr': [img.tolist() for img in train_smote]})\n",
    "train_smote_lab = train_smote['label']\n",
    "\n",
    "# Plot the distribution of the different classes\n",
    "colors = ['#aec7e8', '#ffbb78', '#98df8a', '#ff9896']\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "unique, counts = np.unique(train_smote_lab, return_counts=True)\n",
    "ax.bar(unique, counts, color=colors)\n",
    "ax.set_xticks(unique)\n",
    "ax.set_xticklabels(Lab, rotation=45)\n",
    "ax.set_title('Resampled Training')\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_ylabel('# of images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "504ce240-70b3-44dc-9717-8b818e5be44e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now we see that the training set is balanced across classes. Let's inspect some of the new data for quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ec96ea2-7d96-4347-89c7-578ed3402b79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "first_indices = {}\n",
    "for num in range(0, 4):\n",
    "    first_index = next((i for i, x in enumerate(train_smote_lab[5121:], start=5121) if x == num), None)\n",
    "    first_indices[num] = first_index\n",
    "\n",
    "for label, index in first_indices.items():\n",
    "    if index is not None:\n",
    "        num_synthetic_images = len(train_smote_lab) - index\n",
    "        print(f\"Class {Lab[label]}: {num_synthetic_images} synthetic images\")\n",
    "\n",
    "# Visualize the images from the first_indices values\n",
    "f, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
    "for i, label in enumerate(np.unique(train_smote_lab)):\n",
    "    if first_indices[label] is not None:\n",
    "        first_image = np.array(train_smote.iloc[first_indices[label]]['img_arr']).reshape(128, 128)\n",
    "        ax[i].imshow(first_image, cmap='gray')\n",
    "        ax[i].set_title(f\"{Lab[label]}: SMOTE\")\n",
    "    ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eac4875e-8a5a-4019-83f7-e05d908ad418",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In these cases, SMOTE did not successfully generate accurate synthetic data. While some realistic features are apparent, the overall quality is poor. Therefore, we will attemp to balance classes using a classic augmentation approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8eeb278-7b57-4c08-9976-0f5cde64a35f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_tmp = np.array([img for img in train['img_arr']])\n",
    "train_tmp = train_tmp.reshape(-1, 128, 128, 1)\n",
    "\n",
    "train_lab_tmp = train['label'].values\n",
    "\n",
    "# Calculate class distribution\n",
    "class_counts = Counter(train_lab_tmp)\n",
    "\n",
    "# Split the data by class\n",
    "class_images = {}  # Dictionary to hold images by class\n",
    "class_labels = {}  # Dictionary to hold labels by class\n",
    "\n",
    "for img, label in zip(train_tmp, train_lab_tmp):\n",
    "    if label not in class_images:\n",
    "        class_images[label] = []\n",
    "        class_labels[label] = []\n",
    "    class_images[label].append(img)\n",
    "    class_labels[label].append(label)\n",
    "\n",
    "# Plot one image from class_images\n",
    "label_to_plot = list(class_images.keys())[0]  # Select the first label\n",
    "image_to_plot = class_images[label_to_plot][0]  # Select the first image of that label\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Augment the minority classes\n",
    "max_samples = max(len(images) for images in class_images.values())\n",
    "\n",
    "train_balanced = []  # List to hold all augmented images\n",
    "train_lab_balanced = []  # List to hold all augmented labels\n",
    "\n",
    "for label, images in class_images.items():\n",
    "    num_augmentations = max_samples - len(images)  # How many more samples we need\n",
    "\n",
    "    # Minority class\n",
    "    if num_augmentations > 0:\n",
    "        for img_batch, lab_batch in datagen.flow(np.array(images), np.array([label] * len(images)), batch_size=32):\n",
    "            train_balanced.extend(img_batch)\n",
    "            train_lab_balanced.extend(lab_batch)\n",
    "            num_augmentations -= len(img_batch)\n",
    "            if num_augmentations <= 0:\n",
    "                break\n",
    "    \n",
    "    # Add the original images of the class to the balanced set\n",
    "    train_balanced.extend(images)\n",
    "    train_lab_balanced.extend([label] * len(images))\n",
    "\n",
    "\n",
    "train_balanced = np.array(train_balanced)\n",
    "train_lab_balanced = np.array(train_lab_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf042eb6-ef30-4182-83da-1fa189b993cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Plot examples of original and augmented/generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "416832d6-2145-4035-a39f-45baf7779b16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "# Plot balanced images in order of mild, moderate, non, very mild\n",
    "order = ['Mild', 'Moderate', 'None', 'Very Mild']\n",
    "label_order = [Lab.index(o) for o in order]\n",
    "\n",
    "for i, label in enumerate(label_order):\n",
    "    if Lab[label] != 'None':\n",
    "        balanced_images = [img for img, lab in zip(train_balanced, train_lab_balanced) if lab == label]\n",
    "        image_to_plot = balanced_images[0]  # Select the first balanced image of that label\n",
    "        ax[i].imshow(image_to_plot.reshape(128, 128), cmap='gray')\n",
    "        ax[i].set_title(f\"{Lab[label]}: Balanced\", fontsize=14) \n",
    "    ax[i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbc6b2ef-2976-428e-9d7d-9f4eb90ae4cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We have to assume that the original images were all registerer to a standard space. While the augmentation created new instances of the minority classes, these images are now not in the same anatomical space. Therefore, this introduces a new bias in that important features, such as specific brain structures, cannot be interpreted in the context of classification. This is in contrast to SMOTE - where synethic data was created in the same anatomical space as the original data, the quality was poor and would also lead to feature bias. Therefore, while less than ideal, using the original unbalanced dataset may be the best option in this case. We can still determine if the class inbalance meaningfully impacts the overall or class-specific classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ace3de2-bd92-4abc-8b7a-674d00a921e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Save the preprocessed dataset for model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3875bc6b-5395-4481-92b1-735d0a76f381",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Organize preprocessed data\n",
    "data_preproc = {\n",
    "    'train_data': np.array([img for img in train['img_arr']]),\n",
    "    'train_labels': train['label'].values,\n",
    "    'test_data': np.array([img for img in test['img_arr']]),\n",
    "    'test_labels': test['label'].values\n",
    "}\n",
    "\n",
    "file_name = results_dir / 'data_preprocessed.pkl'\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(data_preproc, f)\n",
    "\n",
    "print(f\"Data saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a902fed9-e1a7-460a-aafb-935020b1d90a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "For models that require X-fold validation, we save a separate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcc69352-4010-4193-bfec-53b628d70f72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Combine training and test sets together\n",
    "data = np.concatenate((data_preproc['train_data'], data_preproc['test_data']), axis=0)\n",
    "labels = np.array(np.concatenate((data_preproc['train_labels'], data_preproc['test_labels']), axis=0))\n",
    "\n",
    "# Split data into 5 train/test sets\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "train_idx_fold = []\n",
    "test_idx_fold = []\n",
    "for train_idx, test_idx in skf.split(labels, labels):\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "    train_idx_fold.append(train_idx)\n",
    "    test_idx_fold.append(test_idx)\n",
    "    \n",
    "    # Check class balance across train/test sets\n",
    "    print(f\"Training class distribution: {Counter(y_train)}\")\n",
    "    print(f\"Testing class distribution: {Counter(y_test)}\")\n",
    "    print()\n",
    "\n",
    "# Organize preprocessed data\n",
    "data_preproc_xfold = {\n",
    "    'data': data,\n",
    "    'labels': labels,\n",
    "    'train_idx_fold': train_idx_fold,\n",
    "    'test_idx_fold': test_idx_fold\n",
    "}\n",
    "\n",
    "file_name = results_dir / 'data_preprocessed_xfold.pkl'\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(data_preproc_xfold, f)\n",
    "\n",
    "print(f\"Data saved to {file_name}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "00_Data_Cleaning",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
