{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee3eca32-5942-4c10-a19f-84e17aad6c7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Utilizes the ResNet50 model for transfer learning, exploring:\n",
    "- Fine-tuning the model to improve classification accuracy (with class weighting)\n",
    "- Prediction accuracy and complexity metrics as a function of model pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ade3180-eaee-420f-b1b2-829033f85097",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \"standard\"\n",
    "import numpy as np\n",
    "\n",
    "# machine learning and statistics\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import applications, models, layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# misc\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# src\n",
    "import sys, os, pickle\n",
    "from pathlib import Path\n",
    "script_dir = Path(os.getcwd()).parent\n",
    "src_dir = script_dir / 'src'\n",
    "sys.path.append(str(src_dir))\n",
    "from visualize import visualize_training, multiclass_summary\n",
    "from custom_pruning import global_prune_model\n",
    "\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "849d4204-28eb-4075-9b98-d440d01601c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Create results directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "018f7e13-4633-4a51-a4d1-25cdd08d7c30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "script_dir = Path(os.getcwd()).parent\n",
    "results_dir_00 = script_dir / 'results' / 'notebook_00'\n",
    "\n",
    "results_dir_03 = script_dir / 'results' / 'notebook_03'\n",
    "os.makedirs(results_dir_03, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f54fd8f-1d24-45c0-b096-3a33417e4506",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load data file and unpack contents\n",
    "file_name = results_dir_00 / 'data_preprocessed.pkl'\n",
    "with open(file_name, 'rb') as f:\n",
    "    data_preproc = pickle.load(f)\n",
    "\n",
    "train_data=data_preproc['train_data']\n",
    "train_lab=data_preproc['train_labels']\n",
    "test_data=data_preproc['test_data']\n",
    "test_lab=data_preproc['test_labels']\n",
    "class_lab = ['Mild', 'Moderate', 'None', 'Very Mild']\n",
    "    \n",
    "# Convert labels to categorical\n",
    "train_lab_cat = to_categorical(train_lab.astype('int8'), num_classes=4)\n",
    "test_lab_cat = to_categorical(test_lab.astype('int8'), num_classes=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8f8c2c9-9522-4139-b9a6-02d8c1e06d4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Load and adapt ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "badf7bb5-9268-416e-8a4c-fb06d4fbcbd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# load ResNet50\n",
    "res_model = applications.ResNet50(\n",
    "    include_top=False,\n",
    "    weights=None,\n",
    "    input_shape=(train_data.shape[1], train_data.shape[2], 3)\n",
    ")\n",
    "clear_output(wait=False)\n",
    "\n",
    "# Freeze all layers except the last block\n",
    "for layer in res_model.layers[:-10]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Print layers to verify\n",
    "for i, layer in enumerate(res_model.layers[140:], start=140):\n",
    "    print(f\"Layer {i}: {layer.name}, Trainable: {layer.trainable}\")\n",
    "\n",
    "# Add a Conv2D layer to convert grayscale images to 3 channels\n",
    "input_layer = layers.Input(shape=(128, 128, 1))\n",
    "x = layers.Conv2D(3, (3, 3), padding='same')(input_layer)\n",
    "x = res_model(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(len(np.unique(train_lab)), activation='softmax')(x)  # Add Dense layer with number of unique classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4aa11a6e-81e5-4b4e-9315-5d7c4ff75e28",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Combine new input layer to ResNet50\n",
    "model = models.Model(inputs=input_layer, outputs=x)\n",
    "std_learning_rate = 1e-4\n",
    "model.compile(optimizer = keras.optimizers.Adam(learning_rate = std_learning_rate),\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_lab),\n",
    "    y=train_lab\n",
    ")\n",
    "class_weights_dict = dict(zip(np.unique(train_lab), class_weights))\n",
    "\n",
    "print(class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ffcf68a-69f9-4753-8013-e2af4df5de47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    train_lab_cat,\n",
    "    epochs=20, \n",
    "    validation_data=(test_data, test_lab_cat),\n",
    "    callbacks=[early_stopping],\n",
    "    class_weight=class_weights_dict\n",
    ")\n",
    "\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad64c158-f3fd-4fe5-bd07-1fb431ba5832",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save model and history files\n",
    "model.save(results_dir_03 / 'model_resnet50.h5')\n",
    "print(f\"Model saved to {results_dir_03 / 'model_resnet50.h5'}\")\n",
    "\n",
    "file_name = results_dir_03 / 'history_resnet50.pkl'\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(history, f)\n",
    "\n",
    "print(f\"Data saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3202b367-b8e9-44f4-bfcb-d956542e157e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfc50245-9bac-4a3a-b68e-836294ff94c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_name = results_dir_03 / 'history_resnet50.pkl'\n",
    "with open(file_name, 'rb') as f:\n",
    "    history = pickle.load(f)\n",
    "clear_output(wait=False)\n",
    "\n",
    "visualize_training(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4d9334b-a311-4d5d-85a7-82edca0b47ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We can see that model training stopped after only 8 epochs due to our early stopping criteria - Validation loss began increasing after the third epoch and never recovered. Ideally, by fine tuning this model by unfreezing layers/parameters, we can obtain a better fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6bd0956-d734-487c-87c1-768b87c5357c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Fine tune the ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9571e6b0-1257-49ce-af24-edc018069b7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "res_model = load_model(results_dir_03 / 'model_resnet50.h5')\n",
    "\n",
    "# Unfreeze last whole convolutional block for fine tuning\n",
    "# (rather than all, since this is a small dataset)\n",
    "fine_tune_at = 143\n",
    "for layer in res_model.get_layer('resnet50').layers[fine_tune_at:]: # only unfreeze layers in ResNet50 backbone\n",
    "  layer.trainable = True\n",
    "\n",
    "# Print layers to verify in resnet50 backbone\n",
    "for i, layer in enumerate(res_model.get_layer('resnet50').layers[140:], start=140):\n",
    "    print(f\"Layer {i}: {layer.name}, Trainable: {layer.trainable}\")\n",
    "\n",
    "std_learning_rate = 1e-5 # use lower learning rate with more trainable layers\n",
    "res_model.compile(\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = std_learning_rate),\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "res_model.summary()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d75a766-6fcf-4f7b-ab02-662029fd77eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Notice how the number of trainable parameters has increased from ~5M to ~15M by unfreezing the last convolutional block of the ResNet50 backbone. This should allow better fitting to the current data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c01f103-2240-447e-a9b0-92022687696c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history_fine_tune = res_model.fit(\n",
    "    train_data,\n",
    "    train_lab_cat,\n",
    "    epochs=20, \n",
    "    validation_data=(test_data, test_lab_cat),\n",
    "    callbacks=[early_stopping],\n",
    "    class_weight=class_weights_dict\n",
    ")\n",
    "\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae345850-7022-4a76-9b3e-d279b5093924",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save model and history files\n",
    "res_model.save(results_dir_03 / 'model_resnet50_fine_tune.h5')\n",
    "print(f\"Model saved to {results_dir_03 / 'model_resnet50_fine_tune.h5'}\")\n",
    "\n",
    "file_name = results_dir_03 / 'history_resnet50_fine_tune.pkl'\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(history_fine_tune, f)\n",
    "\n",
    "print(f\"Data saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fae65e3c-589c-42e3-a5a1-001d2ac089ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_name = results_dir_03 / 'history_resnet50_fine_tune.pkl'\n",
    "with open(file_name, 'rb') as f:\n",
    "    history = pickle.load(f)\n",
    "clear_output(wait=False)\n",
    "\n",
    "visualize_training(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2f9bdc8-6879-4429-8b50-cb6434097664",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Clearly, we can see that we unfreezing additional layers in the ResNet50 model, performance increases dramatically. Performance is not only more stable that the original ResNet50 model and the custom CNN in the previous notebook, but plateaus at a higher overall accuracy. Next, we will see if we can maintain that accuracy when simplifying the model through pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0eb6edc2-4d5f-44e3-87c4-27c54cf1a125",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = load_model(results_dir_03 / 'model_resnet50_fine_tune.h5')\n",
    "\n",
    "# Predict test data\n",
    "prob = model.predict(test_data)\n",
    "clear_output(wait=False)\n",
    "predict_classes = np.argmax(prob, axis=1)\n",
    "result = predict_classes - test_lab\n",
    "result_binary = np.argwhere(result == 0)\n",
    "correct = np.size(result_binary, 0)\n",
    "acc=correct/test_lab.shape[0] * 100\n",
    "\n",
    "print()\n",
    "print(f\"Overall classification accuracy is: {acc:.2f} %\")\n",
    "print()\n",
    "\n",
    "# Visualize summary of predictions\n",
    "multiclass_summary(prob, test_lab, class_lab)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8680e92b-96a7-45ac-a597-1ac8b736958e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "When compared to the tuned CNN from the previous notebook, the fine-tuned ResNet50 exhibits a similar overall accuracy. Nevertheless, the class-specific accuracy and F1 score is greatly improved for the minory class (moderate AD). Furthermore, misclassified samples from this class are most commonly labeled as very mild AD, which is adjacent on the AD spectrum and make more physiological sense. Overall, these improvements appear minor at first, but still paint the most complete picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa1d0ebf-ff48-4d47-a5ab-b45e0f5c1ee4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "While not a pressing need, model pruning can be an important aspect of deep learning architectures, especially when considering deployment in ambulatory situations where portable devices and fast inference speeds will be meaningly factors regarding clinical acceptance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e477a55-54ae-4d11-92cd-e8ecf6f5864f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load fine-tuned model\n",
    "pre_pruned_model = load_model(results_dir_03 / 'model_resnet50_fine_tune.h5')\n",
    "\n",
    "results = []\n",
    "pruning_factors = np.arange(0, 1, 0.05)\n",
    "for factor in pruning_factors:\n",
    "    \n",
    "    # Prune and re-compile model\n",
    "    pruned_model = global_prune_model(pre_pruned_model, pruning_factor=factor)\n",
    "    pruned_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    test_loss, test_accuracy = pruned_model.evaluate(test_data, test_lab_cat, batch_size=32)\n",
    "\n",
    "    # Calculate the number of parameters in the pruned model\n",
    "    total_params = np.sum([np.count_nonzero(layer.get_weights()[0]) for layer in pruned_model.layers if len(layer.get_weights()) > 0])\n",
    "\n",
    "    # Save results\n",
    "    results.append({\n",
    "        'pruning_factor': factor,\n",
    "        'total_params': total_params,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_loss': test_loss\n",
    "    })\n",
    "    \n",
    "clear_output(wait=False)\n",
    "\n",
    "# Save history file\n",
    "file_name = results_dir_03 / 'history_resnet50_fine_tune_pruning.pkl'\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "print(f\"Data saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dc70b24-eb49-4974-b817-a4793cb7843d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load history file\n",
    "file_name = results_dir_03 / 'history_resnet50_fine_tune_pruning.pkl'\n",
    "with open(file_name, 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "clear_output(wait=False)\n",
    "\n",
    "pruning_factors = np.array([result['pruning_factor'] * 100 for result in results])\n",
    "total_params = np.array([result['total_params'] for result in results])\n",
    "test_accuracies = np.array([result['test_accuracy'] * 100 for result in results])\n",
    "test_losses = np.array([result['test_loss'] for result in results])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot Test Accuracy\n",
    "axes[0].plot(pruning_factors, test_accuracies, 'g-')\n",
    "axes[0].set_xlabel('Pruning Factor (%)')\n",
    "axes[0].set_ylabel('Test Accuracy (%)', color='g')\n",
    "axes[0].tick_params(axis='y', labelcolor='g')\n",
    "axes[0].set_title('Test Accuracy vs Pruning Factor')\n",
    "\n",
    "# Plot Test Loss\n",
    "axes[1].plot(pruning_factors, test_losses, 'r-')\n",
    "axes[1].set_xlabel('Pruning Factor (%)')\n",
    "axes[1].set_ylabel('Test Loss', color='r')\n",
    "axes[1].tick_params(axis='y', labelcolor='r')\n",
    "axes[1].set_title('Test Loss vs Pruning Factor')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca3514a7-e9df-4970-b118-72a0d9506917",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "While this is not a true pruning approach as the model is not re-structured after removing weights, this proof-of-concept pseudo-pruning gives us a sense of how many weights are likely to be important. With this, we can estimate that the model can be condensed ~15% without notably reducing performance. "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_ResNet50_transfer_learning",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "venv_alz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
