{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "977baf45-0422-4abc-aea2-e10e685469b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Develops a custom convolutional neural network (CNN) to classify Alzheimer's disease, focusing on:\n",
    "- Class weighting to address class imbalance\n",
    "- Hyperparameter tuning\n",
    "- Distributed training using TensorFlow's MirroredStrategy\n",
    "- The effect of class imbalance on class-specific classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e2c498f-af11-4e5a-844f-7137a3c7b8d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \"standard\"\n",
    "import numpy as np\n",
    "\n",
    "# machine learning and statistics\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# misc\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# src\n",
    "import sys, pickle, os\n",
    "from pathlib import Path\n",
    "script_dir = Path(os.getcwd()).parent\n",
    "src_dir = script_dir / 'src'\n",
    "sys.path.append(str(src_dir))\n",
    "from visualize import visualize_training, multiclass_summary\n",
    "\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61681ce4-97d0-4fb5-823f-5d1658878c26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Create results directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45ae2830-cddd-47f6-84de-ae8053c8f050",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "script_dir = Path(os.getcwd()).parent\n",
    "results_dir_00 = script_dir / 'results' / 'notebook_00'\n",
    "\n",
    "results_dir_02 = script_dir / 'results' / 'notebook_02'\n",
    "os.makedirs(results_dir_02, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa743839-3d89-4451-8416-84bd670659bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load data file and unpack contents\n",
    "file_name = results_dir_00 / 'data_preprocessed.pkl'\n",
    "with open(file_name, 'rb') as f:\n",
    "    data_preproc = pickle.load(f)\n",
    "\n",
    "train_data=data_preproc['train_data']\n",
    "train_lab=data_preproc['train_labels']\n",
    "test_data=data_preproc['test_data']\n",
    "test_lab=data_preproc['test_labels']\n",
    "class_lab = ['Mild', 'Moderate', 'None', 'Very Mild']\n",
    "    \n",
    "# Convert labels to categorical\n",
    "train_lab_cat = to_categorical(train_lab.astype('int8'), num_classes=4)\n",
    "test_lab_cat = to_categorical(test_lab.astype('int8'), num_classes=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04dd10a8-8bb0-451c-bdc6-4cfca23373dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Define custom CNN and distributed training strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f86d26d-3d1c-41b3-b193-d2d11e805d84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # three convolutional layers and one fully connected layer\n",
    "    model = keras.Sequential([\n",
    "        keras.Input(shape = (128, 128, 1)),\n",
    "\n",
    "        keras.layers.Conv2D(\n",
    "            filters=32, \n",
    "            kernel_size=(3, 3), \n",
    "            activation='relu', \n",
    "            kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        keras.layers.Conv2D(\n",
    "            filters=64, \n",
    "            kernel_size=(3, 3), \n",
    "            activation='relu', \n",
    "            kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        keras.layers.Conv2D(\n",
    "            filters=128, \n",
    "            kernel_size=(3, 3), \n",
    "            activation='relu', \n",
    "            kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(256, activation='relu'), # fully connected layer\n",
    "        keras.layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    model = create_model()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "clear_output(wait=False)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cb9b299-53e0-47b7-89bb-a6e8ca8f51cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cdd3187-19e9-42dd-b5ca-6b7013c4d857",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "validation_data = (test_data, test_lab_cat)\n",
    "\n",
    "history = model.fit(\n",
    "    train_data, \n",
    "    train_lab_cat, \n",
    "    epochs=25, \n",
    "    batch_size=32, \n",
    "    validation_data=validation_data, \n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c350cc5-d164-4434-a867-cf14b486731d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save model and history files\n",
    "model.save(results_dir_02 / 'model_custom_CNN.h5')\n",
    "print(f\"Model saved to {results_dir_02 / 'model_custom_CNN.h5'}\")\n",
    "\n",
    "file_name = results_dir_02 / 'history_custom_CNN.pkl'\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(history, f)\n",
    "\n",
    "print(f\"Data saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb7b2eba-8d0b-4218-a6c1-96bed9788ca3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Visualize model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97d6b772-f972-4c4b-97d8-ef60208d37c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_name = results_dir_02 / 'history_custom_CNN.pkl'\n",
    "with open(file_name, 'rb') as f:\n",
    "    history = pickle.load(f)\n",
    "clear_output(wait=False)\n",
    "\n",
    "visualize_training(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8a3dd36-4b6b-4cc3-a156-ac58a196755c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Predict test data, evaluate accuracy and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81b6fdff-df96-40d8-b0f3-1f96ef933549",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = load_model(results_dir_02 / 'model_custom_CNN.h5')\n",
    "\n",
    "# Predict test data\n",
    "prob = model.predict(test_data)\n",
    "clear_output(wait=False)\n",
    "predict_classes = np.argmax(prob, axis=1)\n",
    "result = predict_classes - test_lab\n",
    "result_binary = np.argwhere(result == 0)\n",
    "correct = np.size(result_binary, 0)\n",
    "acc=correct/test_lab.shape[0] * 100\n",
    "\n",
    "print()\n",
    "print(f\"Overall classification accuracy is: {acc:.2f} %\")\n",
    "print()\n",
    "\n",
    "# Visualize summary of predictions\n",
    "multiclass_summary(prob, test_lab, class_lab)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "320a99a1-05db-4808-b83e-dfdd3e17351f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Overall we do not see here a direct link between the test set class accuracies and the number of measurements in the training set. While the majority class (no AD) exhibited the highest accuracy, the minority class (moderate AD) exhibited the second highest. Regardless, we still have a class imbalance problem that has not been addressed. Next we will compute and train with class weights to account for the imbalance by giving more importance to underrepresented classes during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use same model architecture from before\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    model_weighted = create_model()\n",
    "    model_weighted.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_lab),\n",
    "    y=train_lab\n",
    ")\n",
    "class_weights_dict = dict(zip(np.unique(train_lab), class_weights))\n",
    "\n",
    "print(class_weights_dict)\n",
    "\n",
    "# Train with class weights\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "validation_data = (test_data, test_lab_cat)\n",
    "\n",
    "history_weighted = model_weighted.fit(\n",
    "    train_data,\n",
    "    train_lab_cat,\n",
    "    epochs=25,\n",
    "    batch_size=32,\n",
    "    validation_data=validation_data,\n",
    "    callbacks=[early_stopping],\n",
    "    class_weight=class_weights_dict\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and history files\n",
    "model_weighted.save(results_dir_02 / 'model_custom_CNN_weighted.h5')\n",
    "print(f\"Model saved to {results_dir_02 / 'model_custom_CNN_weighted.h5'}\")\n",
    "\n",
    "file_name = results_dir_02 / 'history_custom_CNN_weighted.pkl'\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(history_weighted, f)\n",
    "\n",
    "print(f\"Data saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize weighted model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = results_dir_02 / 'history_custom_CNN_weighted.pkl'\n",
    "with open(file_name, 'rb') as f:\n",
    "    history_weighted = pickle.load(f)\n",
    "clear_output(wait=False)\n",
    "\n",
    "visualize_training(history_weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict test data, evaluate accuracy and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model_weighted = load_model(results_dir_02 / 'model_custom_CNN_weighted.h5')\n",
    "\n",
    "# Predict test data\n",
    "prob = model_weighted.predict(test_data)\n",
    "clear_output(wait=False)\n",
    "predict_classes = np.argmax(prob, axis=1)\n",
    "result = predict_classes - test_lab\n",
    "result_binary = np.argwhere(result == 0)\n",
    "correct = np.size(result_binary, 0)\n",
    "acc=correct/test_lab.shape[0] * 100\n",
    "\n",
    "print()\n",
    "print(f\"Overall classification accuracy is: {acc:.2f} %\")\n",
    "print()\n",
    "\n",
    "# Visualize summary of predictions\n",
    "multiclass_summary(prob, test_lab, class_lab)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7e6dc37-2f01-4b72-b679-ae581e05daa8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "When using class weighted we actually see a drop in overall accuracy from 93.20% to 91.41%; however, the recall score for the two minority classes as improved, indicating improved balance across all classes. This makes sense as the model is sacrificing a bit of overall accuracy to better handle the underrepresented classes.\n",
    "\n",
    "In addition to addressing class imbalance via class weighting, the before examples use a custom CNN with default parameters. As was done with the Random Forest classifier, we can tune the parameters of this model to further optimize performance. Here we redefine the CNN exactly as was done before, but now also specify the parameter space associated with different hyperparameters that we want to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8608ee18-9205-4820-b536-75af25024159",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Same architecture as before, but with hyperparameter ranges\n",
    "def build_model(hp):\n",
    "\n",
    "    model = keras.Sequential([\n",
    "    keras.Input(shape = (128, 128, 1)),  \n",
    "        \n",
    "    keras.layers.Conv2D(\n",
    "        filters = hp.Int('conv_1_filter', min_value = 32, max_value = 128, step = 32), \n",
    "        kernel_size = hp.Choice('conv_1_kernel', values = [3,3]), \n",
    "        activation = 'relu',\n",
    "        kernel_regularizer=keras.regularizers.l2(0.01)), \n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    keras.layers.Conv2D(\n",
    "        filters = hp.Int('conv_2_filter', min_value = 64, max_value = 128, step = 32),\n",
    "        kernel_size = hp.Choice('conv_2_kernel', values = [3,3]),\n",
    "        activation = 'relu',\n",
    "        kernel_regularizer=keras.regularizers.l2(0.01)), \n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    keras.layers.Conv2D(\n",
    "        filters = hp.Int('conv_3_filter', min_value = 96, max_value = 128, step = 32),\n",
    "        kernel_size = hp.Choice('conv_3_kernel', values = [3,3]),\n",
    "        activation = 'relu',\n",
    "        kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(\n",
    "        units=hp.Int('dense_1_units', min_value = 128, max_value = 256, step = 32),\n",
    "        activation='relu',\n",
    "        kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        \n",
    "    keras.layers.Dropout(0.5),\n",
    "        \n",
    "    keras.layers.Dense(4, activation = 'softmax')\n",
    "    ])\n",
    "    \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4])\n",
    "    model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "                  loss = 'categorical_crossentropy',\n",
    "                  metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0878966c-e83a-41a9-8ff9-705a106134ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Initiate tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bac57726-1842-4130-9822-e61f8c18bb5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "script_dir = Path(os.getcwd()).parent\n",
    "tuner_dir = script_dir / 'results' / 'notebook_02' / 'tuner_dir'\n",
    "tuner = kt.Hyperband(build_model, objective='val_accuracy', max_epochs=20, factor=3, directory=tuner_dir, project_name='AD_class')\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3295b515-54bc-4fa6-8c40-75cb62974a3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Run search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37108826-ab82-47cf-8c5d-9b749b1c9ab7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tune parameters on subset of data to conserve time/memory\n",
    "subset = []\n",
    "for label in np.unique(train_lab):\n",
    "    label_indices = np.where(train_lab == label)[0]\n",
    "    np.random.shuffle(label_indices)\n",
    "    subset.extend(label_indices[:int(0.25 * len(label_indices))])\n",
    "subset = np.array(subset)\n",
    "train_data_tune = train_data[subset,:,:]\n",
    "train_lab_tune = train_lab[subset]\n",
    "\n",
    "# Plot bar graph of label distribution in subset\n",
    "label_counts = np.bincount(train_lab_tune)\n",
    "labels = np.arange(len(label_counts))\n",
    "\n",
    "train_lab_tune_cat = to_categorical(train_lab_tune.astype('int8'))\n",
    "test_data_tune = test_data\n",
    "test_lab_tune_cat = to_categorical(test_lab.astype('int8'))\n",
    "\n",
    "# Compute class weights\n",
    "class_weights_tune = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_lab_tune),\n",
    "    y=train_lab_tune\n",
    ")\n",
    "class_weights_dict_tune = dict(enumerate(class_weights_tune))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbe03854-36d7-43ff-82e2-fde78bf2c4b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tuner.search(\n",
    "    train_data_tune,\n",
    "    train_lab_tune_cat,\n",
    "    epochs = 10,\n",
    "    callbacks = [stop_early],\n",
    "    validation_data = (test_data_tune, test_lab_tune_cat),\n",
    "    class_weight = class_weights_dict_tune\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2eb59fcc-d883-41da-869d-5724bbfba65f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Even though this accuracy is lower than expected given the previous results, tuning was performed on a subset of training data and with limited training epochs to conserve time and memory. Nevertheless, training data was randomly sampled and should be representative of the total dataset. Therefore, we will use the best hyperparameters found here for further model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12e8f079-e73c-4f59-84b0-2b5c27ab49ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "# Save best hyperparameters\n",
    "file_name = results_dir_02 / 'best_hps_custom_CNN.pkl'\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(best_hps, f)\n",
    "\n",
    "print(f\"Data saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "575758c9-845b-4566-a614-c5be32f31395",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_name = results_dir_02 / 'best_hps_custom_CNN.pkl'\n",
    "with open(file_name, 'rb') as f:\n",
    "    best_hps = pickle.load(f)\n",
    "clear_output(wait=False)\n",
    "\n",
    "print(f\"\"\"\n",
    "Optimal parameters are as follows:\n",
    "\n",
    "Filter 1 output dim: {best_hps.get('conv_1_filter')}\n",
    "Filter 2 output dim: {best_hps.get('conv_2_filter')}\n",
    "Filter 3 output dim: {best_hps.get('conv_3_filter')}\n",
    "\n",
    "Dense layer units: {best_hps.get('dense_1_units')}\n",
    "\n",
    "Learning Rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c884d7e-f94a-435e-b3a2-3f14b6b3a660",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Re-train with full training data and optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e531b7da-bcdc-40f3-a3f6-278cc7fb8b2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 5)\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    train_lab_cat,\n",
    "    epochs = 25,\n",
    "    callbacks = [stop_early],\n",
    "    validation_data = (test_data, test_lab_cat),\n",
    "    class_weight = class_weights_dict\n",
    "    )\n",
    "\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f2c6d21-dacc-46af-8fe0-266275433ca7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save model and history files\n",
    "model.save(results_dir_02 / 'model_custom_CNN_best_hp.h5')\n",
    "print(f\"Model saved to {results_dir_02 / 'model_custom_CNN_best_hp.h5'}\")\n",
    "\n",
    "file_name = results_dir_02 / 'history_custom_CNN_best_hp.pkl'\n",
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(history, f)\n",
    "\n",
    "print(f\"Data saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb365e05-cdad-42ed-a724-9d70923f4b53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_name = results_dir_02 / 'history_custom_CNN_best_hp.pkl'\n",
    "with open(file_name, 'rb') as f:\n",
    "    history = pickle.load(f)\n",
    "clear_output(wait=False)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))\n",
    "\n",
    "visualize_training(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "813099ef-fa7f-433a-a5bf-82151acca5d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "When compared to the original training strategy, that with optimal hyperparameters clearly maximizes the test accuracy across training. However, lets examine model fit in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29cb35ba-672f-481e-9c27-3e177fb4cd03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = load_model(results_dir_02 / 'model_custom_CNN_best_hp.h5')\n",
    "\n",
    "# Predict test data\n",
    "prob = model.predict(test_data)\n",
    "clear_output(wait=False)\n",
    "predict_classes = np.argmax(prob, axis=1)\n",
    "result = predict_classes - test_lab\n",
    "result_binary = np.argwhere(result == 0)\n",
    "correct = np.size(result_binary, 0)\n",
    "acc=correct/test_lab.shape[0] * 100\n",
    "\n",
    "print()\n",
    "print(f\"Overall classification accuracy is: {acc:.2f} %\")\n",
    "print()\n",
    "\n",
    "# Visualize summary of predictions\n",
    "multiclass_summary(prob, test_lab, class_lab)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a1b0221-a21c-4cd9-8d86-052f5d63210d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In this case, hyperparameter tuning very slightly improved overall classification accuracy, but we still see a nice balance across classes due to the class weighting. In particular, the moderate AD class, which is by far the minority class in the entire dataset, clearly exhibits a strong accuracy. This is in contrast to the unbalanced and untuned model where the accuracy on this class was the weakest. Overall, while likely not perfect, the optimized CNN in the end performs well across all classes and overall."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_custom_CNN",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "venv_alz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
