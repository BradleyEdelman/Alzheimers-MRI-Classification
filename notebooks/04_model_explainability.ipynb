{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b76bea30-6076-4fc5-8efa-3ee9f3107ae2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Explores the explainability of the fine-tuned ResNet50 model using SHapley Additive exPlanations (SHAP):\n",
    "- Identifying key spatial features of Alzheimer's progression.\n",
    "- Investigating misclassifications and performing cluster analyses.\n",
    "- Validating model focus and reliability through SHAP visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1891cba-86ac-42be-918d-b0f7a1eebaa3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# \"standard\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# machine learning and statistics\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import shap\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# misc\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# src\n",
    "import sys\n",
    "sys.path.append('/Workspace/Users/bjedelma@gmail.com/Alzheimers-MRI-Classification/src')\n",
    "from visualize import visualize_training\n",
    "from custom_pruning import global_prune_model\n",
    "from data_io import save_model_s3, load_model_s3, save_pickle_s3, load_pickle_s3\n",
    "\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73185a4c-a4e4-4bd5-9d53-815f1917f43c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Mount AWS S3 bucket containing processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edcab333-f4e3-465f-b0ab-ed32979ba822",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ACCESS_KEY = dbutils.secrets.get(scope=\"brad-aws\", key=\"access_key\")\n",
    "SECRET_KEY= dbutils.secrets.get(scope=\"brad-aws\", key=\"secret_key\")\n",
    "\n",
    "# specify bucket and mount point\n",
    "AWS_S3_BUCKET = \"databricks-workspace-stack-brad-personal-bucket/AD_MRI_classification/raw/\"\n",
    "MOUNT_NAME = f\"/mnt/{AWS_S3_BUCKET.split('/')[-2]}\"\n",
    "SOURCE_URL = f\"s3a://{AWS_S3_BUCKET}\"\n",
    "EXTRA_CONFIGS = { \"fs.s3a.access.key\": ACCESS_KEY, \"fs.s3a.secret.key\": SECRET_KEY}\n",
    "\n",
    "# mount bucket\n",
    "if any(mount.mountPoint == MOUNT_NAME for mount in dbutils.fs.mounts()):\n",
    "    print(f\"{MOUNT_NAME} is already mounted.\")\n",
    "else:\n",
    "    dbutils.fs.mount(SOURCE_URL, MOUNT_NAME, extra_configs = EXTRA_CONFIGS)\n",
    "    print(f\"{MOUNT_NAME} is now mounted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5485de85-03ef-4edb-bf29-63ac5a0a25bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load data file and unpack contents\n",
    "bucket_name=\"databricks-workspace-stack-brad-personal-bucket\"\n",
    "s3_file_name='AD_MRI_classification/preprocessed/data_preprocessed.pkl'\n",
    "data=load_pickle_s3(bucket_name, s3_file_name, dbutils)\n",
    "\n",
    "train_data=data['train_data']\n",
    "train_lab=data['train_labels']\n",
    "test_data=data['test_data']\n",
    "test_lab=data['test_labels']\n",
    "    \n",
    "# Convert labels to categorical\n",
    "train_lab_cat = to_categorical(train_lab.astype('int8'), num_classes=4)\n",
    "test_lab_cat = to_categorical(test_lab.astype('int8'), num_classes=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7243ddb-7d83-4cec-97d1-e2e154a3177b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "It is paramount to explain the image-based features that contribute to classification. In the current context, since the dataset is comprised of registered anatomical MRI, feature importance can implicate certain brain regions in AD disease progression. To do this, we first compute and average SHAP values across the entire dataset to understand the most influential features (pixels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c01595fd-76bf-45c0-b72c-a3570776ea88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load fine-tuned model\n",
    "bucket_name = \"databricks-workspace-stack-brad-personal-bucket\"\n",
    "s3_file_path = 'AD_MRI_classification/results/model_resnet50_fine_tune.h5'\n",
    "pre_pruned_model = load_model_s3(bucket_name, s3_file_path, dbutils)\n",
    "\n",
    "# Initialize SHAP explainer\n",
    "shap_data = test_data.reshape((test_data.shape[0], 128, 128, 1))\n",
    "explainer = shap.GradientExplainer(pre_pruned_model, shap_data)\n",
    "\n",
    "# Compute SHAP values for the entire dataset\n",
    "shap_values_all = explainer.shap_values(shap_data)\n",
    "mean_shap = np.mean(np.abs(shap_values_all), axis=0)\n",
    "\n",
    "# Plot on average image\n",
    "shap_data_mean = np.mean(shap_data, axis=0)\n",
    "shap_data_mean = shap_data_mean.reshape(1, 128, 128, 1)\n",
    "\n",
    "# Visualize SHAP values\n",
    "clear_output(wait=False)\n",
    "shap.image_plot(mean_shap, shap_data_mean) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe4c7f57-e2c1-490b-99b0-bfbed5066ef4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "As there are four classes within this dataset, we can also visualize the SHAP values for each stage of AD individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a54cc59-f273-4a10-9d49-019a32e38c80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "shap_values_class_0 = explainer.shap_values(sample, ranked_outputs=1)\n",
    "shap.image_plot(shap_values_class_0, sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff69992c-f2b7-4ebe-b820-bc019d0790ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "For incorrectly classified samples, visualize SHAP values to identify patterns in feature misinterpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4db0b241-8f76-4c0d-8c00-9cf1080f6e48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "misclassified = np.where(predictions != test_labels)[0]\n",
    "for idx in misclassified[:5]:\n",
    "    shap_values = explainer.shap_values(test_data2[idx:idx+1])\n",
    "    shap.image_plot(shap_values, test_data2[idx:idx+1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68ec47c2-f9a8-42b1-95af-3f37b09946f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Cluster: Group similar samples based on their SHAP value patterns to identify clusters in the decision-making process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "060dbc51-3dc6-4132-86de-a2b7e00c3e4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values_all, test_data2, plot_type=\"bar\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_model_explainability",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
