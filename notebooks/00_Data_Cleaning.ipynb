{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc2df669-e011-40c2-bb0b-6c4862bf482b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Mount AWS S3 bucket containing parquet data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43365984-5715-4007-b89f-06edb0c136dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "AWS_S3_BUCKET = \"databricks-workspace-stack-brad-personal-bucket/AD_MRI_classification/raw/\"\n",
    "KEY_FILE = \"/FileStore/tables/brad_databricks_personal_accessKeys_new.csv\"\n",
    "\n",
    "# extract aws credentials from hidden table \n",
    "aws_keys_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"sep\", \",\").load(KEY_FILE)\n",
    "\n",
    "ACCESS_KEY = aws_keys_df.collect()[0][0]\n",
    "SECRET_KEY = aws_keys_df.collect()[0][1]\n",
    "\n",
    "# specify bucket and mount point\n",
    "MOUNT_NAME = f\"/mnt/{AWS_S3_BUCKET.split('/')[-2]}\"\n",
    "SOURCE_URL = f\"s3a://{AWS_S3_BUCKET}\"\n",
    "EXTRA_CONFIGS = { \"fs.s3a.access.key\": ACCESS_KEY, \"fs.s3a.secret.key\": SECRET_KEY}\n",
    "\n",
    "# mount bucket\n",
    "if any(mount.mountPoint == MOUNT_NAME for mount in dbutils.fs.mounts()):\n",
    "    print(f\"{MOUNT_NAME} is already mounted.\")\n",
    "else:\n",
    "    dbutils.fs.mount(SOURCE_URL, MOUNT_NAME, extra_configs = EXTRA_CONFIGS)\n",
    "    print(f\"{MOUNT_NAME} is now mounted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5899a7b-9ac2-469c-b21e-30eb016b10b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65e36a4e-bb5f-42eb-8e9f-f0395a7cf26d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# \"standard\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# misc\n",
    "import cv2\n",
    "import magic\n",
    "from IPython.display import clear_output\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle\n",
    "import boto3\n",
    "\n",
    "# Preprocessing\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import sys\n",
    "sys.path.append('/Workspace/Users/bjedelma@gmail.com/Alzheimers-MRI-Classification/src')\n",
    "from img_preprocessing import dict_to_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88c86944-8205-4dc3-a9ba-9d852fbe442f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Load and format training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4912930-6b72-42cd-ab99-c4f6d0e050fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"C:/Users/bedelman/Documents/GitHub/Alzheimers-MRI-Classification/data/raw/\"\n",
    "\n",
    "'''\n",
    "Label meanings\n",
    "0 - Mild dementia\n",
    "1 - Moderate dementia\n",
    "2 - No dementia\n",
    "3 - Very mild dementia\n",
    "'''\n",
    "Lab = ['Mild', 'Moderate', 'None', 'Very Mild']\n",
    "\n",
    "train = pd.read_parquet(\"/dbfs/mnt/AD_classification/train-00000-of-00001-c08a401c53fe5312.parquet\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "722ba5cf-59c5-477b-b1fa-ce8837170fac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Convert data to readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f7f9bf2-f58d-4ce3-8aef-08034bddf7c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train['img_arr'] = train['image'].apply(dict_to_image)\n",
    "train.drop(\"image\", axis=1, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4463288-f8b0-4e62-b996-383ff115d51a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Load and convert test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38cba496-0db1-42e8-a909-5bccdd473593",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_parquet(\"/dbfs/mnt/AD_classification/test-00000-of-00001-44110b9df98c5585.parquet\")\n",
    "test.head() \n",
    "\n",
    "# Also convert to readable format\n",
    "test['img_arr'] = test['image'].apply(dict_to_image)\n",
    "test.drop(\"image\", axis=1, inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8c90a59-2056-40a7-86fa-070e086ed5f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Examine some sample images to check data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aba0af47-cd93-49ac-8bd5-83dbecd72118",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_lab_idx = np.asarray(train.iloc[:].label)\n",
    "\n",
    "f, ax = plt.subplots(4,4)\n",
    "for lab in range(4):\n",
    "    for ex in range(4):\n",
    "    \n",
    "        class_lab = np.argwhere(train_lab_idx == 1)\n",
    "        current_idx = np.random.randint(len(class_lab)-1,size = 1)\n",
    "        current_idx = np.asarray(current_idx)\n",
    "        \n",
    "        ax[ex, lab].axis('off')\n",
    "        ax[ex, lab].imshow(train.iloc[class_lab[current_idx[0]][0]].img_arr, cmap = \"gray\")\n",
    "        if ex == 0: ax[ex, lab].set_title(Lab[lab])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6e166e0-d0ef-4c78-8672-69ba9c61ddf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Clearly, images show different slices within the brain, which may be a major confound..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37c1167a-06db-4d09-8ac0-d297dfd663ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Explore distribution of dataset classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c712bf20-7bb4-4a15-92d7-951d2eadf5ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "colors = ['#aec7e8', '#ffbb78', '#98df8a', '#ff9896']\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "unique, counts = np.unique(np.asarray(train.iloc[:].label), return_counts=True)\n",
    "ax[0].bar(unique, counts, color=colors)\n",
    "ax[0].set_xticks(unique)\n",
    "ax[0].set_xticklabels(Lab, rotation=45)\n",
    "ax[0].set_title('Training')\n",
    "ax[0].set_xlabel('Class')\n",
    "ax[0].set_ylabel('# of images')\n",
    "\n",
    "unique, counts = np.unique(np.asarray(test.iloc[:].label), return_counts=True)\n",
    "ax[1].bar(unique, counts, color=colors)\n",
    "ax[1].set_xticks(unique)\n",
    "ax[1].set_xticklabels(Lab, rotation=45)\n",
    "ax[1].set_title('Testing')\n",
    "ax[1].set_xlabel('Class')\n",
    "ax[1].set_ylabel('# of images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6809d477-1e10-4d52-8d16-59b7029afdfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We can see that there is an obvious imbalance across classes in both the training and testing sets. However, each class has been proportionally split between the two. Nevertheless, let's attempt to balance the training set such that the model sees equal numbers of each class. To avoid overfitting (e.g. simple resampling), we use the SMOTE method here to synthetically generate new data based on what is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38ba78fe-66f4-453c-8e3c-ade2660fa07c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Extract features and labels\n",
    "X_train = np.array([img.flatten() for img in train['img_arr']])\n",
    "y_train = train['label']\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "train_smote, train_smote_lab = smote.fit_resample(X_train.reshape(-1, 128*128), y_train)\n",
    "train_smote = train_smote.reshape(-1, 128, 128)\n",
    "\n",
    "# Create a new DataFrame with the resampled data\n",
    "train_smote = pd.DataFrame({'label': train_smote_lab, 'img_arr': [img.tolist() for img in train_smote]})\n",
    "train_smote_lab = train_smote['label']\n",
    "\n",
    "# Plot the distribution of the different classes\n",
    "colors = ['#aec7e8', '#ffbb78', '#98df8a', '#ff9896']\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "unique, counts = np.unique(train_smote_lab, return_counts=True)\n",
    "ax.bar(unique, counts, color=colors)\n",
    "ax.set_xticks(unique)\n",
    "ax.set_xticklabels(Lab, rotation=45)\n",
    "ax.set_title('Resampled Training')\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_ylabel('# of images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "504ce240-70b3-44dc-9717-8b818e5be44e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now we see that the training set is balanced across classes. Let's inspect some of the new data for quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ec96ea2-7d96-4347-89c7-578ed3402b79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "first_indices = {}\n",
    "for num in range(0, 4):\n",
    "    first_index = next((i for i, x in enumerate(train_smote_lab[5121:], start=5121) if x == num), None)\n",
    "    first_indices[num] = first_index\n",
    "\n",
    "print(first_indices)\n",
    "\n",
    "# Visualize the images from the first_indices values\n",
    "f, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
    "for i, label in enumerate(np.unique(train_smote_lab)):\n",
    "    if first_indices[label] is not None:\n",
    "        first_image = np.array(train_smote.iloc[first_indices[label]]['img_arr']).reshape(128, 128)\n",
    "        ax[i].imshow(first_image, cmap='gray')\n",
    "        ax[i].set_title(f\"{Lab[label]}: SMOTE\")\n",
    "    ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eac4875e-8a5a-4019-83f7-e05d908ad418",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fdd23d13-fe7e-4ca8-b0e2-e3fcee58f6fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Rather the balancing classes with SMOTE, let's augment the existing data to expand and balance the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8eeb278-7b57-4c08-9976-0f5cde64a35f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_tmp = np.array([img for img in train['img_arr']])\n",
    "train_tmp = train_tmp.reshape(-1, 128, 128, 1)\n",
    "\n",
    "train_lab_tmp = train['label'].values\n",
    "\n",
    "# Create ImageDataGenerator object\n",
    "datagen = ImageDataGenerator()\n",
    "\n",
    "# Create a balanced dataset using ImageDataGenerator\n",
    "train_balanced = []\n",
    "train_lab_balanced = []\n",
    "for class_label in np.unique(train_lab_tmp):\n",
    "    class_indices = np.where(train_lab_tmp == class_label)[0]\n",
    "    class_images = train_tmp[class_indices]\n",
    "    class_labels = train_lab_tmp[class_indices]\n",
    "    \n",
    "    # Generate more images to balance the classes\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    for X_batch, y_batch in datagen.flow(class_images, class_labels, batch_size=len(class_images)):\n",
    "        train_balanced.extend(X_batch)\n",
    "        train_lab_balanced.extend(y_batch)\n",
    "        if len(train_balanced) >= len(train_tmp):\n",
    "            break\n",
    "\n",
    "# Convert balanced data and labels to numpy arrays\n",
    "train_balanced = np.array(train_balanced)\n",
    "train_lab_balanced = np.array(train_lab_balanced)\n",
    "\n",
    "# Create a new DataFrame with the balanced data\n",
    "train_balanced = pd.DataFrame({'label': train_lab_balanced, 'img_arr': [img.tolist() for img in train_balanced]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "416832d6-2145-4035-a39f-45baf7779b16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of the different classes in the style and color scheme as above\n",
    "colors = ['#aec7e8', '#ffbb78', '#98df8a', '#ff9896']\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left subplot: Class distribution\n",
    "unique, counts = np.unique(train['label'], return_counts=True)\n",
    "ax[0].bar(unique, counts, color=colors)\n",
    "ax[0].set_xticks(unique)\n",
    "ax[0].set_xticklabels(Lab, rotation=45)\n",
    "ax[0].set_title('Class Distribution')\n",
    "ax[0].set_xlabel('Class')\n",
    "ax[0].set_ylabel('# of images')\n",
    "\n",
    "# Right subplot: Images created by the data generator for all classes\n",
    "for i, label in enumerate(np.unique(balanced_labels)):\n",
    "    first_image = balanced_data[np.where(balanced_labels == label)][0].reshape(128, 128)\n",
    "    ax[1].imshow(first_image, cmap='gray')\n",
    "    ax[1].set_title(f\"{Lab[label]}: Generated\")\n",
    "    ax[1].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07a30b46-eba9-4bc1-8a62-74a11274f1e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "91bf4857-8bee-4178-ab01-c699f616a634",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for i in range(len(train)):\n",
    "    train_data.append(np.reshape(train.iloc[i].img_arr, (1, -1)))    \n",
    "train_data = np.vstack(train_data[:])\n",
    "\n",
    "# decompose with PCA and look at various metrics/info\n",
    "pca = PCA(n_components = 100)\n",
    "pca.fit(train_data)\n",
    "\n",
    "plt.plot(np.linspace(1,100,100),pca.explained_variance_[:100]/sum(pca.explained_variance_[:100])*100,'b')\n",
    "plt.title('PCA')\n",
    "plt.xlabel('Component #')\n",
    "plt.ylabel('Variance Explained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3af046f-6f93-4ee8-988e-4027b92856d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "load_train = np.matmul(train_data, loadings[:,:2])\n",
    "\n",
    "# plot first two PCs\n",
    "s  = plt.scatter(load_train[:,0], load_train[:,1], c = train_lab_idx*2, cmap = 'tab10', alpha = 0.75)\n",
    "handles, labels = s.legend_elements()\n",
    "legend = plt.legend(handles = handles, labels = Lab, title = 'Diagnosis', loc = 'upper right')\n",
    "plt.axis('off')\n",
    "plt.title('PCA projections')\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3875bc6b-5395-4481-92b1-735d0a76f381",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Prepare the data to be saved\n",
    "data_to_save = {\n",
    "    'train_data_balanced': train_data,\n",
    "    'train_labels_balanced': train_lab_idx,\n",
    "    'pca': pca\n",
    "}\n",
    "\n",
    "# Define the file path\n",
    "file_path = '/Workspace/Users/bjedelma@gmail.com/Alzheimers-MRI-Classification/data/preprocessed/train_data_preprocessed.pkl'\n",
    "\n",
    "# Save the data using pickle\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(data_to_save, file)\n",
    "\n",
    "# Upload to S3 bucket\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'databricks-workspace-stack-brad-personal-bucket'\n",
    "s3_file_path = 'AD_MRI_classification/raw/train_data_preprocessed.pkl'\n",
    "\n",
    "s3.upload_file(file_path, bucket_name, s3_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e552b82-b5df-4f83-a692-842f2d0e261e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import types\n",
    "import setuptools\n",
    "\n",
    "# List all libraries used in this notebook\n",
    "libraries_used = [\n",
    "    'numpy',\n",
    "    'matplotlib',\n",
    "    'pickle'\n",
    "]\n",
    "\n",
    "# Get the current versions installed\n",
    "installed_packages = {pkg.key: pkg.version for pkg in setuptools.working_set}\n",
    "\n",
    "# Filter the versions of the libraries used\n",
    "libraries_versions = {lib: installed_packages[lib] for lib in libraries_used if lib in installed_packages}\n",
    "\n",
    "display(libraries_versions)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "00_Data_Cleaning",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "PYSPARK_KERNEL",
   "language": "python",
   "name": "pyspark_kernel"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
