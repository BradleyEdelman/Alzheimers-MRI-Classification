{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc2df669-e011-40c2-bb0b-6c4862bf482b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Mount AWS S3 bucket containing parquet data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43365984-5715-4007-b89f-06edb0c136dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "AWS_S3_BUCKET = \"databricks-workspace-stack-brad-personal-bucket/AD_MRI_classification/raw/\"\n",
    "KEY_FILE = \"/FileStore/tables/brad_databricks_personal_accessKeys_new.csv\"\n",
    "\n",
    "# extract aws credentials from hidden table \n",
    "aws_keys_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"sep\", \",\").load(KEY_FILE)\n",
    "\n",
    "ACCESS_KEY = aws_keys_df.collect()[0][0]\n",
    "SECRET_KEY = aws_keys_df.collect()[0][1]\n",
    "\n",
    "# specify bucket and mount point\n",
    "MOUNT_NAME = f\"/mnt/{AWS_S3_BUCKET.split('/')[-2]}\"\n",
    "SOURCE_URL = f\"s3a://{AWS_S3_BUCKET}\"\n",
    "EXTRA_CONFIGS = { \"fs.s3a.access.key\": ACCESS_KEY, \"fs.s3a.secret.key\": SECRET_KEY}\n",
    "\n",
    "# mount bucket\n",
    "if any(mount.mountPoint == MOUNT_NAME for mount in dbutils.fs.mounts()):\n",
    "    print(f\"{MOUNT_NAME} is already mounted.\")\n",
    "else:\n",
    "    dbutils.fs.mount(SOURCE_URL, MOUNT_NAME, extra_configs = EXTRA_CONFIGS)\n",
    "    print(f\"{MOUNT_NAME} is now mounted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5899a7b-9ac2-469c-b21e-30eb016b10b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65e36a4e-bb5f-42eb-8e9f-f0395a7cf26d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# \"standard\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# misc\n",
    "import cv2\n",
    "import magic\n",
    "from IPython.display import clear_output\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle\n",
    "import boto3\n",
    "from collections import Counter\n",
    "\n",
    "# Preprocessing\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.decomposition import PCA\n",
    "import sys\n",
    "sys.path.append('/Workspace/Users/bjedelma@gmail.com/Alzheimers-MRI-Classification/src')\n",
    "from img_preprocessing import dict_to_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88c86944-8205-4dc3-a9ba-9d852fbe442f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Load and format training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4912930-6b72-42cd-ab99-c4f6d0e050fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Label meanings\n",
    "0 - Mild dementia\n",
    "1 - Moderate dementia\n",
    "2 - No dementia\n",
    "3 - Very mild dementia\n",
    "'''\n",
    "Lab = ['Mild', 'Moderate', 'None', 'Very Mild']\n",
    "\n",
    "train = pd.read_parquet(\"/dbfs/mnt/AD_classification/raw/train-00000-of-00001-c08a401c53fe5312.parquet\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "722ba5cf-59c5-477b-b1fa-ce8837170fac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Convert data to readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f7f9bf2-f58d-4ce3-8aef-08034bddf7c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train['img_arr'] = train['image'].apply(dict_to_image)\n",
    "train.drop(\"image\", axis=1, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4463288-f8b0-4e62-b996-383ff115d51a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Load and convert test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38cba496-0db1-42e8-a909-5bccdd473593",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_parquet(\"/dbfs/mnt/AD_classification/raw/test-00000-of-00001-44110b9df98c5585.parquet\")\n",
    "test.head() \n",
    "\n",
    "# Also convert to readable format\n",
    "test['img_arr'] = test['image'].apply(dict_to_image)\n",
    "test.drop(\"image\", axis=1, inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8c90a59-2056-40a7-86fa-070e086ed5f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Examine some sample images to check data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aba0af47-cd93-49ac-8bd5-83dbecd72118",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_lab_idx = np.asarray(train.iloc[:].label)\n",
    "\n",
    "f, ax = plt.subplots(4, 4, figsize=(5, 5))\n",
    "for lab in range(4):\n",
    "    for ex in range(4):\n",
    "    \n",
    "        class_lab = np.argwhere(train_lab_idx == 1)\n",
    "        current_idx = np.random.randint(len(class_lab)-1,size = 1)\n",
    "        current_idx = np.asarray(current_idx)\n",
    "        \n",
    "        ax[ex, lab].axis('off')\n",
    "        ax[ex, lab].imshow(train.iloc[class_lab[current_idx[0]][0]].img_arr, cmap = \"gray\")\n",
    "        if ex == 0: ax[ex, lab].set_title(Lab[lab])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6e166e0-d0ef-4c78-8672-69ba9c61ddf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Clearly, images show different slices within the brain, which may be a major confound..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37c1167a-06db-4d09-8ac0-d297dfd663ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Explore distribution of dataset classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c712bf20-7bb4-4a15-92d7-951d2eadf5ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "colors = ['#aec7e8', '#ffbb78', '#98df8a', '#ff9896']\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "unique, counts = np.unique(np.asarray(train.iloc[:].label), return_counts=True)\n",
    "ax[0].bar(unique, counts, color=colors)\n",
    "ax[0].set_xticks(unique)\n",
    "ax[0].set_xticklabels(Lab, rotation=45)\n",
    "ax[0].set_title('Training')\n",
    "ax[0].set_xlabel('Class')\n",
    "ax[0].set_ylabel('# of images')\n",
    "\n",
    "unique, counts = np.unique(np.asarray(test.iloc[:].label), return_counts=True)\n",
    "ax[1].bar(unique, counts, color=colors)\n",
    "ax[1].set_xticks(unique)\n",
    "ax[1].set_xticklabels(Lab, rotation=45)\n",
    "ax[1].set_title('Testing')\n",
    "ax[1].set_xlabel('Class')\n",
    "ax[1].set_ylabel('# of images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6809d477-1e10-4d52-8d16-59b7029afdfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We can see that there is an obvious imbalance across classes in both the training and testing sets. However, each class has been proportionally split between the two. Nevertheless, let's attempt to balance the training set such that the model sees equal numbers of each class. To avoid overfitting (e.g. simple resampling), we use the SMOTE method here to synthetically generate new data based on what is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38ba78fe-66f4-453c-8e3c-ade2660fa07c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Extract features and labels\n",
    "train_tmp = np.array([img.flatten() for img in train['img_arr']])\n",
    "train_lab_tmp = train['label']\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "train_smote, train_smote_lab = smote.fit_resample(train_tmp.reshape(-1, 128*128), train_lab_tmp)\n",
    "train_smote = train_smote.reshape(-1, 128, 128)\n",
    "\n",
    "# Create a new DataFrame with the resampled data\n",
    "train_smote = pd.DataFrame({'label': train_smote_lab, 'img_arr': [img.tolist() for img in train_smote]})\n",
    "train_smote_lab = train_smote['label']\n",
    "\n",
    "# Plot the distribution of the different classes\n",
    "colors = ['#aec7e8', '#ffbb78', '#98df8a', '#ff9896']\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "unique, counts = np.unique(train_smote_lab, return_counts=True)\n",
    "ax.bar(unique, counts, color=colors)\n",
    "ax.set_xticks(unique)\n",
    "ax.set_xticklabels(Lab, rotation=45)\n",
    "ax.set_title('Resampled Training')\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_ylabel('# of images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "504ce240-70b3-44dc-9717-8b818e5be44e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now we see that the training set is balanced across classes. Let's inspect some of the new data for quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ec96ea2-7d96-4347-89c7-578ed3402b79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "first_indices = {}\n",
    "for num in range(0, 4):\n",
    "    first_index = next((i for i, x in enumerate(train_smote_lab[5121:], start=5121) if x == num), None)\n",
    "    first_indices[num] = first_index\n",
    "\n",
    "print(first_indices)\n",
    "\n",
    "# Visualize the images from the first_indices values\n",
    "f, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
    "for i, label in enumerate(np.unique(train_smote_lab)):\n",
    "    if first_indices[label] is not None:\n",
    "        first_image = np.array(train_smote.iloc[first_indices[label]]['img_arr']).reshape(128, 128)\n",
    "        ax[i].imshow(first_image, cmap='gray')\n",
    "        ax[i].set_title(f\"{Lab[label]}: SMOTE\")\n",
    "    ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eac4875e-8a5a-4019-83f7-e05d908ad418",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fdd23d13-fe7e-4ca8-b0e2-e3fcee58f6fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Rather the balancing classes with SMOTE, let's augment the existing data to expand and balance the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8eeb278-7b57-4c08-9976-0f5cde64a35f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_tmp = np.array([img for img in train['img_arr']])\n",
    "train_tmp = train_tmp.reshape(-1, 128, 128, 1)\n",
    "\n",
    "train_lab_tmp = train['label'].values\n",
    "\n",
    "# Calculate class distribution\n",
    "class_counts = Counter(train_lab_tmp)\n",
    "\n",
    "# Split the data by class\n",
    "class_images = {}  # Dictionary to hold images by class\n",
    "class_labels = {}  # Dictionary to hold labels by class\n",
    "\n",
    "for img, label in zip(train_tmp, train_lab_tmp):\n",
    "    if label not in class_images:\n",
    "        class_images[label] = []\n",
    "        class_labels[label] = []\n",
    "    class_images[label].append(img)\n",
    "    class_labels[label].append(label)\n",
    "\n",
    "# Plot one image from class_images\n",
    "label_to_plot = list(class_images.keys())[0]  # Select the first label\n",
    "image_to_plot = class_images[label_to_plot][0]  # Select the first image of that label\n",
    "\n",
    "# Augment the minority classes\n",
    "max_samples = max(len(images) for images in class_images.values())\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_balanced = []  # List to hold all augmented images\n",
    "train_lab_balanced = []  # List to hold all augmented labels\n",
    "for label, images in class_images.items():\n",
    "    num_augmentations = max_samples - len(images)  # How many more samples we need to augment\n",
    "\n",
    "    # Augment the minority class\n",
    "    if num_augmentations > 0:\n",
    "        for img_batch, lab_batch in datagen.flow(np.array(images), np.array([label] * len(images)), batch_size=32):\n",
    "            train_balanced.extend(img_batch)\n",
    "            train_lab_balanced.extend(lab_batch)\n",
    "            num_augmentations -= len(img_batch)\n",
    "            if num_augmentations <= 0:\n",
    "                break\n",
    "    \n",
    "    # Add the original images of the class to the balanced set\n",
    "    train_balanced.extend(images)\n",
    "    train_lab_balanced.extend([label] * len(images))\n",
    "\n",
    "\n",
    "train_balanced = np.array(train_balanced)\n",
    "train_lab_balanced = np.array(train_lab_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "416832d6-2145-4035-a39f-45baf7779b16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2, len(class_images), figsize=(20, 10))\n",
    "\n",
    "# Plot original images\n",
    "for i, (label, images) in enumerate(class_images.items()):\n",
    "    image_to_plot = images[0]  # Select the first image of that label\n",
    "    ax[0, i].imshow(image_to_plot.reshape(128, 128), cmap='gray')\n",
    "    ax[0, i].set_title(f\"{Lab[label]}\")  # Label the classes according to labels\n",
    "    ax[0, i].axis('off')\n",
    "\n",
    "# Plot balanced images\n",
    "for i, (label, images) in enumerate(class_images.items()):\n",
    "    balanced_images = [img for img, lab in zip(train_balanced, train_lab_balanced) if lab == label]\n",
    "    image_to_plot = balanced_images[0]  # Select the first balanced image of that label\n",
    "    ax[1, i].imshow(image_to_plot.reshape(128, 128), cmap='gray')\n",
    "    ax[1, i].set_title(f\"{Lab[label]}: Balanced\")  # Label the classes according to labels\n",
    "    ax[1, i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07a30b46-eba9-4bc1-8a62-74a11274f1e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91bf4857-8bee-4178-ab01-c699f616a634",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for i in range(len(train_balanced)):\n",
    "    train_data.append(np.reshape(train_balanced[i], (1, -1)))    \n",
    "train_data = np.vstack(train_data[:])\n",
    "\n",
    "# decompose with PCA and look at various metrics/info\n",
    "pca = PCA(n_components = 100)\n",
    "pca.fit(train_data)\n",
    "\n",
    "plt.plot(np.linspace(1,100,100),pca.explained_variance_[:100]/sum(pca.explained_variance_[:100])*100,'b')\n",
    "plt.title('PCA')\n",
    "plt.xlabel('Component #')\n",
    "plt.ylabel('Variance Explained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3af046f-6f93-4ee8-988e-4027b92856d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "loadings = pca.components_.T * np.sqrt(pca.explained_variance_)\n",
    "load_train = np.matmul(train_data, loadings[:,:2])\n",
    "\n",
    "# plot first two PCs\n",
    "s  = plt.scatter(load_train[:,0], load_train[:,1], c = train_lab_idx*2, cmap = 'tab10', alpha = 0.75)\n",
    "handles, labels = s.legend_elements()\n",
    "legend = plt.legend(handles = handles, labels = Lab, title = 'Diagnosis', loc = 'upper right')\n",
    "plt.axis('off')\n",
    "plt.title('PCA projections')\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3875bc6b-5395-4481-92b1-735d0a76f381",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Prepare the data to be saved\n",
    "data_to_save = {\n",
    "    'train_data_balanced': train_data,\n",
    "    'train_labels_balanced': train_lab_idx,\n",
    "    'pca': pca\n",
    "}\n",
    "\n",
    "# Define the file path\n",
    "file_path = '/Workspace/Users/bjedelma@gmail.com/Alzheimers-MRI-Classification/data/preprocessed/train_data_preprocessed.pkl'\n",
    "\n",
    "# Save the data using pickle\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(data_to_save, file)\n",
    "\n",
    "# Upload to S3 bucket\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'databricks-workspace-stack-brad-personal-bucket'\n",
    "s3_file_path = 'AD_MRI_classification/raw/train_data_preprocessed.pkl'\n",
    "\n",
    "s3.upload_file(file_path, bucket_name, s3_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e552b82-b5df-4f83-a692-842f2d0e261e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import types\n",
    "import setuptools\n",
    "\n",
    "# List all libraries used in this notebook\n",
    "libraries_used = [\n",
    "    'numpy',\n",
    "    'matplotlib',\n",
    "    'pickle'\n",
    "]\n",
    "\n",
    "# Get the current versions installed\n",
    "installed_packages = {pkg.key: pkg.version for pkg in setuptools.working_set}\n",
    "\n",
    "# Filter the versions of the libraries used\n",
    "libraries_versions = {lib: installed_packages[lib] for lib in libraries_used if lib in installed_packages}\n",
    "\n",
    "display(libraries_versions)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "00_Data_Cleaning",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "PYSPARK_KERNEL",
   "language": "python",
   "name": "pyspark_kernel"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
